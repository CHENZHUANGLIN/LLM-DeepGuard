#!/bin/bash

# Project Cerberus - SecGPT ç¯å¢ƒå¿«é€Ÿå¯åŠ¨è„šæœ¬

echo "ğŸ›¡ï¸ Project Cerberus"
echo "ç¯å¢ƒ: SecGPT"
echo ""

# è®¾ç½® Ollama æ¨¡å‹å­˜å‚¨ç›®å½•
export OLLAMA_MODELS="/8lab/CHEN/ollama/models"
export OLLAMA_LOG_DIR="/8lab/CHEN/ollama/logs"
export PATH="/usr/local/bin:$PATH"

# è·å– conda è·¯å¾„
CONDA_BASE=$(conda info --base 2>/dev/null)

if [ -z "$CONDA_BASE" ]; then
    echo "âŒ æœªæ‰¾åˆ° Conda"
    echo "è¯·å…ˆå®‰è£…: https://docs.conda.io/en/latest/miniconda.html"
    exit 1
fi

# æ¿€æ´»ç¯å¢ƒ
source "$CONDA_BASE/etc/profile.d/conda.sh"
conda activate SecGPT

if [ $? -ne 0 ]; then
    echo "âŒ SecGPT ç¯å¢ƒæœªå®‰è£…"
    echo "è¯·å…ˆè¿è¡Œ: ./install_SecGPT.sh"
    exit 1
fi

echo "âœ… SecGPT ç¯å¢ƒå·²æ¿€æ´»"
echo ""

# æ˜¾ç¤ºåŸºç¡€ä¿¡æ¯
echo "ğŸ Python: $(python --version 2>&1)"

# æ£€æŸ¥ CUDA
if command -v nvidia-smi &> /dev/null; then
    GPU_NAME=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1)
    GPU_MEM=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
    echo "ğŸ”¥ GPU: $GPU_NAME (${GPU_MEM} MB)"
fi

# Ollama é…ç½®
echo "ğŸ“‚ Ollama æ¨¡å‹: $OLLAMA_MODELS"

# æ£€æŸ¥å¹¶å¯åŠ¨ Ollama
if ! pgrep -x "ollama" > /dev/null; then
    echo "âš ï¸  Ollama æœåŠ¡æœªè¿è¡Œï¼Œæ­£åœ¨å¯åŠ¨..."
    mkdir -p "$OLLAMA_LOG_DIR"
    # ç¡®ä¿åœæ­¢æ—§çš„ç³»ç»ŸæœåŠ¡
    sudo systemctl stop ollama 2>/dev/null || true
    nohup ollama serve > "$OLLAMA_LOG_DIR/ollama.log" 2>&1 &
    sleep 3
    if pgrep -x "ollama" > /dev/null; then
        echo "âœ… Ollama å·²å¯åŠ¨ (PID: $(pgrep -x ollama))"
    else
        echo "âŒ Ollama å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—: $OLLAMA_LOG_DIR/ollama.log"
    fi
else
    echo "âœ… Ollama æœåŠ¡è¿è¡Œä¸­ (PID: $(pgrep -x ollama))"
fi

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ“š å¯ç”¨å‘½ä»¤ï¼š"
echo "  python main.py --generate-data    # ç”Ÿæˆæ•°æ®"
echo "  python main.py --train            # å®Œæ•´è®­ç»ƒ"
echo "  python main.py --train-sft        # ä»… SFT"
echo "  python main.py --train-dpo        # ä»… DPO"
echo "  python main.py --evaluate         # è¯„ä¼°ç³»ç»Ÿ"
echo "  python main.py                    # äº¤äº’æ¨¡å¼"
echo ""
echo "ğŸ“– æ–‡æ¡£ï¼š"
echo "  cat README.md                     # é¡¹ç›®æ–‡æ¡£"
echo ""
echo "ğŸ”§ ç¯å¢ƒç®¡ç†ï¼š"
echo "  conda deactivate                  # é€€å‡ºç¯å¢ƒ"
echo "  nvidia-smi                        # GPU çŠ¶æ€"
echo "  ollama list                       # æŸ¥çœ‹æ¨¡å‹"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

# å¯åŠ¨äº¤äº’å¼ shell
exec bash --rcfile <(echo ". ~/.bashrc; conda activate SecGPT; export OLLAMA_MODELS='/8lab/CHEN/ollama/models'; PS1='(SecGPT) \[\033[01;32m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]\$ '")
